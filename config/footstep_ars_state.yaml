# Added args
wandb_project: footstep

# existing args from pytorch_a2c_ppo_acktr_gail, defaults changed
algo: ars
lr: 0.0015
n_dirs: 10
top_dirs: 8
delta_std: 0.025
top_dirs_frac: null
eval_int: 10
eval_runs: 1
save_int: 100
env_name: aliengo
n_samples: 100_000_000


env_params:
  # fixed: False
  # fixed_position: [0.0, 0.0, 0.48]
  # fixed_orientation: [0.0, 0.0, 0.0]
  stochastic_resets: True
  obstacles: null
  render: False
  apply_perturb: False
  avg_time_per_perturb: 5.0 # seconds
  action_repeat: 4
  max_torque: 44.4 # from URDF
  kp: 1.0
  kd: 1.0
  observation_parts: #TODO enumerate all possible types that I can even put here. Also add terrain heightmaps
    # - joint_torques
    # - joint_positions
    # - joint_velocities
    - robo_frame_foot_position
    - robo_frame_foot_velocity
    - base_angular_velocity
    - base_position
    - base_orientation
    - base_velocity
    # - base_roll
    # - base_pitch
    - current_footstep_foot_one_hot
    # - next_footstep_distance
    - footstep_distance_one_hot
    - previous_action
    - previous_observation
    - foot_contact_states
    # - base_linear_acceleration #TODO

  # possible values ['joint_positions', 'joint_velocities', 'joint_torques']
  # eventually add pmtg and footstep_param stuff
  # null means to use the widest bounds allowed ie no additional restriction imposed
  action_space:
    # joint_positions: #TODO implement the bounds and other action spaces.
    #   lb: null
    #   ub: null
    foot_positions:
      lb: [-0.5, -0.3, -0.53]
      ub: [0.5, 0.3, -0.15]

  reward_parts: #TODO
    # reward_type: coefficient
    # note: the reward bounds are on the measured value of the thing, not on the reward term
    # forward_velocity: [1.0, -1.5, 1.5] #coeffient, lower bound, upper bound
    velocity_towards_footstep: [0.25, -0.5, 0.5] # coefficient, min, max
    footstep_reached: [10.0, 0.03] # [coeff, distance_treshhold (m)] this must be included to increment footsteps
    joint_torques_sq: [-0.000005]
    smoothness_sq: [0.1]
    orientation: [-1.0, 0.1, 0.1, 0.02]

  footstep_params:
    step_length: 0.05
    step_length_rand: 0.01 # range of uniform distribution to randomize step len by
    step_width: 0.25
    step_width_rand: 0.01
    base_length: 0.45 # this is the distance between front and back legs nominally
    length_offset: -0.02
    n_cycles: 2 # how many cycles of 4 footsteps to generate in the training env
    gait: walk
    footstep_rand: 0.02 # range of uniform displacement to apply to every footstep

  termination_conditions: #obstacles and foostep_param will automatically include their own termination conditions (ie traveling outside of generated terrain)
    height_bounds: [0.23, 0.8] # [lb, ub] this will automatically be turned off if obstacles are included
    orientation_bounds: [0.5, 0.25, 0.25] # multiples of pi
    timeout: [10] # seconds


