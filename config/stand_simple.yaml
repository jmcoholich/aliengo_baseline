# Added args
wandb_project: default
gpu_idx: 0

# existing args from pytorch_a2c_ppo_acktr_gail, defaults changed
algo: ppo
gail: False # do imitation learning with  gail
gail_experts_dir: ./gail_experts #directory that contains expert demonstrations for gail
gail_batch_size: 128
gail_epoch: 5
lr: 3.0e-4
eps: 1.0e-5 # RMSprop optimizer epsilon (default: 1e-5)
alpha: 0.99 # RMSprop optimizer apha (default: 0.99)
gamma: 0.99
use_gae: True
gae_lambda: 0.95
entropy_coef: 0.00
value_loss_coef: 0.5
max_grad_norm: 0.5
seed: 1
cuda_deterministic: False
num_processes: 20
num_steps: 60
ppo_epoch: 10
num_mini_batch: 32
clip_param: 0.2
log_interval: 100
save_interval: 10
eval_interval: null
num_env_steps: 1_000_000
env_name: aliengo
wandb_log_interval: 1 #TODO
log_dir: /tmp/gym/
# save_dir: ./trained_models/
cuda: False
use_proper_time_limits: True
recurrent_policy: False
use_linear_lr_decay: False
num_torch_threads: null # null just means don't set anything.


env_params:
  obstacles: null
  render: False
  # env_mode: pmtg
  apply_perturb: False
  avg_time_per_perturb: 5.0 # seconds
  action_repeat: 4 # TODO change back to 6
  # timeout: 60.0 # number of seconds to timeout after
  # flat_ground: True # this is for getting terrain scan in privileged info for Aliengo
  vis: False
  max_torque: 44.4 # from URDF
  kp: 1.0
  kd: 1.0
  fixed: False
  fixed_position: [0,0,1.0] #TODO remove
  fixed_orientation: [0,0,0] #TODO remove
  gait_type: trot
  observation_parts: #TODO enumerate all possible types that I can even put here. Also add terrain heightmaps
    # - joint_torques
    - joint_positions
    # - joint_velocities
    # - base_angular_velocity
    # - base_roll
    # - base_pitch
    # - base_linear_acceleration #TODO

  # possible values ['joint_positions', 'joint_velocities', 'joint_torques']
  # eventually add pmtg and footstep_param stuff
  # null means to use the widest bounds allowed ie no additional restriction imposed
  action_space:
    # joint_positions: #TODO implement the bounds and other action spaces.
    #   lb: null
    #   ub: null
    one_leg_only: #TODO implement the bounds and other action spaces.
      lb: null
      ub: null

  reward_parts: #TODO
    # reward_type: coefficient
    # note: the reward bounds are on the measured value of the thing, not on the reward term
    # forward_velocity: [1.0, -1.5, 1.5] #coeffient, lower bound, upper bound
    joint_torques_l2: [-0.000005]
    existance: [1.0]

  termination_conditions: #obstacles and foostep_param will automatically include their own termination conditions (ie traveling outside of generated terrain)
    height_bounds: [0.23, 0.8] # [lb, ub] this will automatically be turned off if obstacles are included
    orientation_bounds: [0.5, 0.25, 0.25] # multiples of pi
    timeout: [10] # seconds