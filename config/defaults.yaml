# Added args
wandb_project: default
gait_type: trot
gpu_idx: 0

# existing args from pytorch_a2c_ppo_acktr_gail, defaults changed
algo: ppo
gail: False # do imitation learning with  gail
gail_experts_dir: ./gail_experts #directory that contains expert demonstrations for gail
gail_batch_size: 128
gail_epoch: 5
lr: 3.0e-5
eps: 1.0e-5 # RMSprop optimizer epsilon (default: 1e-5)
alpha: 0.99 # RMSprop optimizer apha (default: 0.99)
gamma: 0.99
use_gae: True
gae_lambda: 0.95
entropy_coef: 0.00
value_loss_coef: 0.5
max_grad_norm: 0.5
seed: 1
cuda_deterministic: False
num_processes: 1 #TODO
num_steps: 10 #TODO 600
ppo_epoch: 10
num_mini_batch: 10 # TODO 32
clip_param: 0.2
log_interval: 1 #TODO
save_interval: 100
eval_interval: null
num_env_steps: 100_000_000
env_name: aliengo
wandb_log_interval: 1 #TODO
log_dir: /tmp/gym/
# save_dir: ./trained_models/
cuda: True # changed from no_cuda to simplify
use_proper_time_limits: True
recurrent_policy: False
use_linear_lr_decay: False
num_torch_threads: null # null just means don't set anything.


env_params:
  obstacles: steps
  render: False #TODO
  # env_mode: pmtg
  apply_perturb: False
  avg_time_per_perturb: 5.0 # seconds
  action_repeat: 4 # TODO change back to 6
  timeout: 60.0 # number of seconds to timeout after
  flat_ground: True # this is for getting terrain scan in privileged info for Aliengo 
  realTime: False # should never be True when training, only for visualzation or debugging MAYBE
  vis: False
  max_torque: 44.4 # from URDF 
  kp: 1.0  
  kd: 1.0 
  fixed: False 
  fixed_position: [0,0,1.0] 
  fixed_orientation: [0,0,0]
  vis: False
  gait_type: trot
  observation_parts: #TODO enumerate all possible types that I can even put here. Also add terrain heightmaps
    - joint_torques
    - joint_positions
    - joint_velocities
    - base_angular_velocity
    - base_roll
    - base_pitch
    # - base_linear_acceleration #TODO

  # possible values ['joint_positions', 'joint_velocities', 'joint_torques'] 
  # eventually add pmtg and footstep_param stuff
  # null means to use the widest bounds allowed ie no additional restriction imposed
  action_parts: 
    joint_positions:
      lb: null
      ub: null
  
  # reward_parts: #TODO
  #   # reward_type: coefficient
  #   forward_velocity: asdf
